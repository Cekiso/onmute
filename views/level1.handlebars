<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="/timeout.js"></script>

    {{!--
    <link rel="stylesheet" href="/css/skeleton.css"> --}}

    {{!--
    <link rel="stylesheet" href="../public/style.css"> --}}

    <title>Document</title>
    <style>
        body {
            background-color: lightseagreen;
            color: whitesmoke;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        .overall {
            margin: auto;
            width: 50%;
            background-color: crimson;
            text-align: center;
            justify-content: center;
            align-content: center;
            border: solid black;
            border-radius: 25%;
            background-image: linear-gradient(rgba(6, 4, 110, 0.8), rgba(143, 163, 142, 0.8)), url(./—Pngtree—cool\ technology\ sense\ information\ technology_1046698.jpg);
        }

        .back1 a button {
            width: 150px;
            height: 50px;
            background-color: whitesmoke;
            border: 1px solid wheat;
            color: black;
            outline: none;
            transition: .6s ease;
            border-radius: 25px;
            margin: 9%;
        }

        .allOptions {
            display: flex;
        }

        .back1 a button:hover {
            cursor: pointer;
            background-color: rgb(238, 232, 221);
            color: black;
            box-shadow: 0 0 5px white, 0 0 10px white, 0 0 15px white;
            font-weight: bold;
        }

        .button button {
            width: 100px;
            height: 50px;
            background-color: whitesmoke;
            border: 1px solid wheat;
            color: black;
            outline: none;
            transition: .6s ease;
            border-radius: 25px;
        }

        .button button:hover {
            cursor: pointer;
            background-color: rgb(238, 232, 221);
            color: black;
            box-shadow: 0 0 5px white, 0 0 10px white, 0 0 15px white;
            font-weight: bold;
        }

        .question text {
            color: solid red;
        }
    </style>




</head>

<body>
    <div class="overall">

        <h2>LEVEL1</h2>
        <form action="Level1" method="POST">
            <div class="question" name="question">{{challenge}}</div>
            
            <button type="button" onclick="init()" class="start">Start</button>
            <button type="button" onclick="stop()" class="start">stop</button>

            <div><canvas id="canvas"></canvas></div>
            <div id="label-container"></div>
            <div class="results"></div>
            <div class="button">
                <a href="./level2"> <button>Next</button></a>
            </div>
            <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
            <script
                src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
            <script type="text/javascript">
                // More API functions here:
                // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose
                // the link to your model provided by Teachable Machine export panel
                const URL = "https://teachablemachine.withgoogle.com/models/9RE6vl80w/";
                let model, webcam, ctx, labelContainer, maxPredictions, showResults, button;
                async function init() {
                    const modelURL = URL + "model.json";
                    const metadataURL = URL + "metadata.json";
                    // load the model and metadata
                    // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
                    // Note: the pose library adds a tmPose object to your window (window.tmPose)
                    model = await tmPose.load(modelURL, metadataURL);
                    maxPredictions = model.getTotalClasses();
                    // Convenience function to setup a webcam
                    const size = 200;
                    const flip = true; // whether to flip the webcam
                    webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
                    await webcam.setup(); // request access to the webcam
                    await webcam.play();
                    window.requestAnimationFrame(loop);
                    // append/get elements to the DOM
                    const canvas = document.getElementById("canvas");
                    canvas.width = size; canvas.height = size;
                    ctx = canvas.getContext("2d");
                    labelContainer = document.getElementById("label-container");
                    showResults = document.querySelector('.results')
                    button = document.querySelector('.button')
                    // showResults.innerHTML = "You are  correct "
                    for (let i = 0; i < maxPredictions; i++) { // and class labels
                        labelContainer.appendChild(document.createElement("div"));
                    }
                }
                async function loop(timestamp) {
                    webcam.update(); // update the webcam frame
                    await predict();
                    window.requestAnimationFrame(loop);
                }
                /////////////////////////////////////////
                  async function challenge(id) {
                 await pool.query(`select challenge_name from challenge where id=$1 `,[id]);
                // return challenge_name.rows;
                 return 'it working';

    }
                async function predict() {
                    let maxPredi = 0;
                    let classNameLabel;
                    // Prediction #1: run input through posenet
                    // estimatePose can take in an image, video or canvas html element
                    const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
                    // Prediction 2: run input through teachable machine classification model
                    const prediction = await model.predict(posenetOutput);

                    for (let props of prediction) {
                        if (props.probability > maxPredi) {
                            maxPredi = props.probability
                            classNameLabel = props.className

                            console.log(maxPredi.toFixed(2) + 'maxPredict');
                            console.log(classNameLabel + "uuuuuuuuuuu");
                            // classNameLabel = 'Yes'

                            if (classNameLabel === 'Yes' && maxPredi >= 0.88) {
                                showResults.innerHTML = 'You are correct'
                                stop()

                            }
                            if (classNameLabel === 'Finish') {
                                showResults.innerHTML = 'Finish'

                            }
                            if (classNameLabel === 'Me') {
                                showResults.innerHTML = 'Me'

                            }
                            if (classNameLabel === 'More') {
                                showResults.innerHTML = 'More'

                            }

                        }
                        console.log(showResults.innerHTML + "qqqqqqqqqq");
                    }
                    //     const classPrediction =
                    //         prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                    labelContainer.innerHTML = classNameLabel;
                    // }
                    // finally draw the poses
                    drawPose(pose);
                }
                function drawPose(pose) {
                    if (webcam.canvas) {
                        ctx.drawImage(webcam.canvas, 0, 0);
                        // draw the keypoints and skeleton
                        if (pose) {
                            const minPartConfidence = 0.5;
                            tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
                            tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
                        }
                    }
                }
                async function stop() {
                    await webcam.stop()
                    console.log('stoping');
                }
            </script>
            <div class="allOptions">
                <div class="option1">



                </div>
                <div class="option2">



                </div>
                <div class="option3">


                </div>
        </form>
    </div>

    {{#each levels}}
    <ul>
        <a href="/counter/{{game}}">{{game}}</a>
    </ul>
    {{/each}}

    <div class="back1">
        <a href="/"> <button>Home</button></a>
    </div>
    <form action="./level2" method="post">

    </form>
    </form>


</body>

</html>